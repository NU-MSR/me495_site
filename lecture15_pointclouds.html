<!-- Generated with pandoc -D html
Modified by Matthew Elwin.
-->
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<meta name="author" content="Matthew Elwin" />
<title>3-D Sensing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
</style>
<!--[if lt IE 9]>
<script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
<![endif]-->
<style type="text/css">
/*
Matthew Elwin
css for the nume template for making websites

Contains code modified from with https://gist.github.com/killercup/5917178
Mostly using the aesthetics from above, but added a table of contents menu to the left.
When printing, the menu will be hidden

*/


nav#TOC{
    width: 20%;
    height: 100%;
    position:fixed!important;
    z-index:1;
    overflow:auto;
    padding-right: 2em;
}

.home_up{
    position: fixed;
    right: 0.25em;
    top: 0.25em;
}
.content{
    margin-left: 21%;
    padding-left: 4em;
}

.inner{
    margin: 0 auto;
    min-width: 30em;
    max-width: 50em;
}

.no-foot{
    min-height: 100vh 
}

.container:after,.container:before{content:"";display:table;clear:both}

.footer {
    font-size: 9pt
}

html {
  font-size: 100%;
  overflow-y: scroll;
  -webkit-text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  padding: 0;
}

body {
  font-family: "DejaVu Serif", Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman', serif;
  font-size: 12px;
  line-height: 1.7;
  padding: 1em;
  background: #fefefe;
}

a {
  color: #0645ad;
  text-decoration: none;
}

a:visited {
  color: #0b0080;
}

nav a:visited {
    color: #0645ad;
}

a:hover {
  color: #06e;
}

nav a:hover {
    color: #0645ad;
    background: #C3C3DE
}

a:active {
  color: #faa700;
}

a:focus {
  outline: thin dotted;
}

*::-moz-selection {
  background: rgba(255, 255, 0, 0.3);
  color: #000;
}

*::selection {
  background: rgba(255, 255, 0, 0.3);
  color: #000;
}

a::-moz-selection {
  background: rgba(255, 255, 0, 0.3);
  color: #0645ad;
}

a::selection {
  background: rgba(255, 255, 0, 0.3);
  color: #0645ad;
}

p {
  margin: 1em 0;
}

img {
  max-width: 100%;
}

h1, h2, h3, h4, h5, h6 {
  color: #111;
  line-height: 125%;
  margin-top: 1em;
  font-weight: normal;
}

h4, h5, h6 {
  font-weight: bold;
}

h1 {
  font-size: 2.5em;
}

h1.title {
    margin-top: 0em;
    font-size: 3em;
}

h2 {
  font-size: 2em;
}

h3 {
  font-size: 1.5em;
}

h4 {
  font-size: 1.2em;
}

h5 {
  font-size: 1em;
}

h6 {
  font-size: 0.9em;
}

blockquote {
  color: #666666;
  margin: 0;
  padding-left: 3em;
  border-left: 0.5em #EEE solid;
}

hr {
  display: block;
  height: 2px;
  border: 0;
  border-top: 1px solid #aaa;
  border-bottom: 1px solid #eee;
  margin: 1em 0;
  padding: 0;
}

pre, code, kbd, samp {
    color: #000;
    background-color: #f0f0f0;
  border: 1px solid #e1e4e5;
  font-family: monospace, monospace;
  _font-family: 'courier new', monospace;
  font-size: 0.98em;
  line-height: normal;
}

.line-block {
    color: #000;
    background-color: #f0f0f0;
    border: 1px solid #e1e4e5;
}
/* this style is used for inline code blocks 
it is overwridden when inside a pre format block*/
code {
    padding: 0 5px;
    white-space: nowrap;
    font-size: 85%
}

pre {
  white-space: pre;
  white-space: pre-wrap;
  word-wrap: break-word;
}

pre code {
    padding: 0 0;
    white-space: inherit;
    border: 0
}

b, strong {
  font-weight: bold;
}

dfn {
  font-style: italic;
}

ins {
  background: #ff9;
  color: #000;
  text-decoration: none;
}

mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

sub, sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}

sup {
  top: -0.5em;
}

sub {
  bottom: -0.25em;
}

ul, ol {
  margin: 1em 0;
  padding: 0 0 0 2em;
}

li > ul, li > ol {
    margin: 0 0;
}

nav ul, nav ol {
    list-style: none;
    padding: 0 0 0 0;
}

/* make the top level list item in table of contents not indent*/
nav li > ul, nav li > ol {
    list-style: none;
    padding: 0 0 0 2em;
}

li p:last-child {
  margin-bottom: 0;
}

ul ul, ol ol {
  margin: .3em 0;
}

dl {
  margin-bottom: 1em;
}

dt {
  font-weight: bold;
  margin-bottom: .8em;
}

dd {
  margin: 0 0 .8em 2em;
}

dd:last-child {
  margin-bottom: 0;
}

img {
  border: 0;
  -ms-interpolation-mode: bicubic;
  vertical-align: middle;
}

figure {
  display: block;
  text-align: center;
  margin: 1em 0;
}

figure img {
  border: none;
  margin: 0 auto;
}

figcaption {
  font-size: 0.8em;
  font-style: italic;
  margin: 0 0 .8em;
}

table {
  margin-bottom: 2em;
  border-bottom: 1px solid #ddd;
  border-right: 1px solid #ddd;
  border-spacing: 0;
  border-collapse: collapse;
}

table th {
  padding: .2em 1em;
  background-color: #eee;
  border-top: 1px solid #ddd;
  border-left: 1px solid #ddd;
}

table td {
  padding: .2em 1em;
  border-top: 1px solid #ddd;
  border-left: 1px solid #ddd;
  vertical-align: top;
}

.author {
  font-size: 1.2em;
}

/* When the screen gets too narrow, hide the toc*/
@media only screen and (max-width: 768px) {
    nav {
        visibility: hidden
    }
    .content {
        margin-left: 0;
    }
}

@media only screen and (min-width: 480px) {
  body {
      font-size: 14px;
  }
}
@media only screen and (min-width: 768px) {
  body {
    font-size: 16px;
  }
}
@media print {
  * {
    background: transparent !important;
    color: black !important;
    filter: none !important;
    -ms-filter: none !important;
  }

  nav {
      visibility: hidden;
  }

  .content{
      margin-left: 0%;
      padding-left: 10px;
  }

  body {
    font-size: 10pt;
    max-width: 100%;
  }

  a, a:visited {
    text-decoration: underline;
  }

  hr {
    height: 1px;
    border: 0;
    border-bottom: 1px solid black;
  }

  a[href]:after {
    content: " (" attr(href) ")";
  }

  abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
    content: "";
  }

  pre, blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  tr, img {
    page-break-inside: avoid;
  }

  img {
    max-width: 100% !important;
  }

  @page :left {
    margin: 15mm 20mm 15mm 10mm;
}

  @page :right {
    margin: 15mm 10mm 15mm 20mm;
}

  p, h2, h3 {
    orphans: 3;
    widows: 3;
  }

  h2, h3 {
    page-break-after: avoid;
  }
}


</style> 
</head>
<body>

<!-- Sidebar for table of contents -->
<nav id="TOC" role="doc-toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#depth-image">Depth Image</a>
<ul>
<li><a href="#structured-light">Structured Light</a></li>
<li><a href="#stereo-depth">Stereo Depth</a></li>
<li><a href="#time-of-flight">Time of Flight</a></li>
</ul></li>
<li><a href="#point-clouds">Point Clouds</a>
<ul>
<li><a href="#how-to-point-cloud">How To Point Cloud</a></li>
</ul></li>
<li><a href="#devices-that-generate-point-clouds">Devices that Generate Point Clouds</a>
<ul>
<li><a href="#intel-realsense">Intel RealSense</a></li>
<li><a href="#using-the-realsense-in-ros">Using the Realsense In ROS</a></li>
</ul></li>
<li><a href="#manipulating-point-clouds">Manipulating Point Clouds</a>
<ul>
<li><a href="#ros">ROS</a></li>
<li><a href="#c">C++</a></li>
<li><a href="#python">Python</a></li>
</ul></li>
<li><a href="#demonstration">Demonstration</a></li>
<li><a href="#resources">Resources</a></li>
</ul>
</nav>

<nav class="home_up">
  <a href="index.html">Home</a>
</nav>
<div class="content">
  <div class="inner">
    <div class="no-foot">
<!-- Put the header to the right of the table of contents -->
<header id="title-block-header">
<h1 class="title">3-D Sensing</h1>
</header>

<!-- The main content of the file -->
<h1 id="depth-image">Depth Image</h1>
<p>A depth image or depth map is a 2D dimensional image where each pixel value corresponds to the distance of an object from the camera. There are several methods for generating a depth image.</p>
<h2 id="structured-light">Structured Light</h2>
<ol>
<li>An active light emitter outputs a pattern</li>
<li>Objects deform the pattern</li>
<li>Image sensor senses the pattern and, using the distortion, computes the depth map</li>
<li>Good for indoors and short range, because they require seing the projected patterns.</li>
<li>Can be interfered with when, for example, there are multiple devices outputting patterns</li>
</ol>
<h2 id="stereo-depth">Stereo Depth</h2>
<ol>
<li>Two images taken some known fixed distance apart</li>
<li>By comparing the images taken from known different angles, the depth can be known</li>
<li>The farther an object is from the sensors, the more similar the two images are</li>
<li>No active light emission is required so they do not interfere with each other.</li>
<li>Range is limited by distance between the two sensors.</li>
<li>Active IR can be used to create known features and enhance the accuracy</li>
</ol>
<h2 id="time-of-flight">Time of Flight</h2>
<ul>
<li>LiDar</li>
<li>Measure depth by emitting light and timing how long it takes to reach the sensor</li>
<li>Very long range</li>
</ul>
<h1 id="point-clouds">Point Clouds</h1>
<ul>
<li>A Point Cloud is a group of 3 dimensional coordinates (points) that constitute a discrete description of 3-dimensional objects.</li>
<li>The <a href="https://pointclouds.org">point cloud library</a> contains routines for manipulating point clouds</li>
<li><a href="https://wiki.ros.org/perception_pcl">perception pcl</a> ROS meta-package for point clouds</li>
<li><a href="http://wiki.ros.org/pcl_ros/Tutorials">Point Cloud Tutorials</a></li>
</ul>
<h2 id="how-to-point-cloud">How To Point Cloud</h2>
<ol>
<li>A depth map provides the distance from the camera in pixel coordinates</li>
<li>Using a camera calibration, this depth map is converted into real-world x,y,z coordinates</li>
<li>The pixels can be superimposed with data taken from an RGB camera to provide a 3D image</li>
</ol>
<h1 id="devices-that-generate-point-clouds">Devices that Generate Point Clouds</h1>
<ul>
<li>Lidars/Laser Scanners <a href="http://wiki.ros/org/velodyne">Velodyne</a> <a href="http://wiki.ros.node/urg_node">SCIP 2.2 laser range-finders</a></li>
<li>Stereo Cameras
<ul>
<li><a href="https://www.stereolabs.com/zed/">ZED</a></li>
<li><a href="https://www.flir.com/support/products/bumblebee2-firewire/?page=4#Overview">Bumblebee 2</a></li>
</ul></li>
<li>Depth Cameras
<ul>
<li><a href="http://www.intelrealsense.com">RealSense</a></li>
<li><a href="http://wiki.ros.org/openni2_launch">opennni</a> (Like the Asus Xtion 2)</li>
<li>Kinect for Box 360 using <a href="http://wiki.ros.org/freenect_launch">freenect_launch</a></li>
<li>Kinect for Xbox One using <a href="https://github.com/code-iai/iai_kinect2">iai_kinect2</a></li>
</ul></li>
</ul>
<h2 id="intel-realsense">Intel RealSense</h2>
<ul>
<li>The <a href="https://www.intelrealsense.com/depth-camera-d435i/">Intel Realsense D435i</a> is an active stereo depth camera</li>
<li>The realsense drivers and library are not yet released for Ubuntu 20.04 and the ros package is not yet released for ROS noetic</li>
<li>Follow my <a href="./realsense.html">instructions</a> for installation</li>
</ul>
<h2 id="using-the-realsense-in-ros">Using the Realsense In ROS</h2>
<p>There are 3 ways of using the realsense in ROS. Official documentation is here for using SDK 2.0: <a href="https://dev.intelrealsense.com/docs/docs-get-started">https://dev.intelrealsense.com/docs/docs-get-started</a></p>
<ol>
<li>Use <code>librealsense</code> from C++</li>
<li>Use <code>librealsense</code> python wrappers</li>
<li>Use the ROS node: For example, <code>roslaunch realsense2_camera rs_camera.launch filters:=pointcloud</code>.
<ul>
<li>This is the easiest version to use for the most part</li>
<li>Usage instructions are on the github page <a href="https://github.com/IntelRealSense/realsense-ros">https://github.com/IntelRealSense/realsense-ros</a></li>
<li>Visualize the pointcloud by adding a PointCloud2 object in rviz</li>
</ul></li>
<li>There are some <a href="https://github.com/ros-visualization/rviz/issues/1508">Bugs</a> in rviz on some systems for seeing pointclouds.
<ul>
<li>Here is what I observed
<ol>
<li>Running =rviz –opengl 300 fixes most of the issues (point cloud is visible but it gets messed up when window is maximized)</li>
<li>Running =rviz –opengl 210 fixes most of the issues (point cloud is visible but it gets messed up when window is maximized)</li>
<li>Running <code>rviz</code> you need to set the visualization type to <code>points</code> and make sure the window is not maximized to avoid this issue</li>
</ol></li>
<li>Recommendation: run rviz with the <code>--opengl 300</code> flag when you want to view point clouds</li>
</ul></li>
</ol>
<h1 id="manipulating-point-clouds">Manipulating Point Clouds</h1>
<p>There are several ways of manipulating point clouds in ROS.</p>
<h2 id="ros">ROS</h2>
<ul>
<li>In ROS, point clouds are sent using the <a href="http://docs.ros.org/en/api/sensor_msgs/html/msg/PointCloud2.html">sensor_msgs/PointCloud2</a> message
<ul>
<li>You can access the message fields directly but the format is not the most intuitive</li>
</ul></li>
<li>The <a href="http://wiki.ros.org/pcl_ros">pcl_ros</a> package is the primary ROS package for manipulating pointclouds</li>
<li>It includes several stand-alone filters that can be loaded as nodelets to perform common operations</li>
</ul>
<h2 id="c">C++</h2>
<ul>
<li>The <a href="http://wiki.ros.org/pcl_ros">pcl_ros</a> package also lets you convert point cloud messages into C++ data types for use with the <a href="https://pointclouds.org">Point Cloud Library</a>
<ul>
<li>While this is the most common way of handling point clouds in ROS, it is also a C++ only way</li>
</ul></li>
</ul>
<h2 id="python">Python</h2>
<ul>
<li>The <a href="http://wiki.ros.org/sensor_msgs">sensor_msgs</a> package has python tools for manipulating Pointloud2 data
<ul>
<li>See the <a href="http://docs.ros.org/en/noetic/api/sensor_msgs/html/namespacesensor__msgs_1_1point__cloud2.html">point_cloud2</a> API</li>
<li>See <a href="https://answers.ros.org/question/325917/pointcloud-value-at-a-given-index/">This ROS answer</a> for some details on how to index into the pointcloud.</li>
</ul></li>
<li>The <a href="https://wiki.ros.org/ros_numpy">ros_numpy</a> package lets you convert many ROS message types (including PointCloud2) into easy-to-use numpy arrays
<ul>
<li>You can use this package to convert a point cloud into a numpy array, manipulate, and then convert back into a pointcloud message</li>
</ul></li>
<li>You can install python bindings for pcl using pip (<code>pip3 install python-pcl</code>) or as an Ubuntu package (<code>sudo apt install python3-pcl</code>)
<ul>
<li>The <a href="https://strawlab.github.io/python-pcl/">python-pcl</a> package mostly parallels the C++ pcl API</li>
<li>This <a href="https://stackoverflow.com/questions/39772424/how-to-effeciently-convert-ros-pointcloud2-to-pcl-point-cloud-and-visualize-it-i">Answer</a> demonstrates how to convert data from a PointCloud2 message into a <code>pcl.PointCloud</code> object</li>
</ul></li>
</ul>
<h1 id="demonstration">Demonstration</h1>
<p>The following code demonstrates using some basic pcl "nodelets". Nodelets are essentially ROS nodes that can all be run in a single process to reduce communication overhead. The <a href="https://github.com/NU-MSR/nodelet_pcl_demo">Nodelet PCL demo</a> shows you how to combine several built-in nodelets to filter point cloud data. There is then a C++ node that uses the point cloud library (PCL) to perform additional processing.</p>
<h1 id="resources">Resources</h1>
<p><a href="https://www.intelrealsense.com/beginners-guide-to-depth/">Beginner's guide to depth</a></p>
</div>
<div class="footer">
Author: Matthew Elwin.
</div>
</div>
</div>

</body>
</html>
